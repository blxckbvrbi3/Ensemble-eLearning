{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Boosting : F1 Score 0.95, Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "clf_boosting = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "clf_boosting.fit(train_x, train_y)\n",
    "predictions = clf_boosting.predict(test_x)\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway:\n",
    "\n",
    "We can see that the accurecy of the Boosting method is relativly high. This is an accurecy level that would be rather difficult to get from an individual model in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "clf_bagging = RandomForestClassifier(n_estimators=200, max_depth=1)\n",
    "clf_bagging.fit(train_x, train_y)\n",
    "predictions = clf_bagging.predict(test_x)\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.9\n",
      "For Boosting : F1 Score 0.93, Accuracy 0.94\n",
      "For Stacking : F1 Score 0.98, Accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=2020)\n",
    "\n",
    "boosting_clf_ada_boost= AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=3\n",
    ")\n",
    "bagging_clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "clf_ada_boost = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1,random_state=2020),\n",
    "    n_estimators=3\n",
    ")\n",
    "\n",
    "clf_logistic_reg = LogisticRegression(solver='liblinear',random_state=2020)\n",
    "\n",
    "#Customizing and Exception message\n",
    "class NumberOfClassifierException(Exception):\n",
    "    pass\n",
    "\n",
    "#Creating a stacking class\n",
    "class Stacking():\n",
    "\n",
    "    '''\n",
    "        This is a test class for stacking !\n",
    "        Please fill Free to change it to fit your needs\n",
    "        We suppose that at least the First N-1 Classifiers have\n",
    "        a predict_proba function.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,classifiers):\n",
    "        if(len(classifiers) < 2):\n",
    "            raise numberOfClassifierException(\"You must fit your classifier with 2 classifiers at least\");\n",
    "        else:\n",
    "            self._classifiers = classifiers\n",
    "\n",
    "\n",
    "    def fit(self,data_x,data_y):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            classfier.fit(data_x,data_y)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,classfier.predict_proba(data_x)))\n",
    "\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        last_classifier.fit(stacked_data_x,data_y)\n",
    "\n",
    "\n",
    "    def predict(self,data_x):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            prob_predictions = classfier.predict_proba(data_x)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,prob_predictions))\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        return last_classifier.predict(stacked_data_x)\n",
    "\n",
    "\n",
    "\n",
    "bagging_clf_rf.fit(train_x, train_y)\n",
    "boosting_clf_ada_boost.fit(train_x, train_y)\n",
    "\n",
    "classifers_list = [clf_rf,clf_ada_boost,clf_logistic_reg]\n",
    "clf_stacking = Stacking(classifers_list)\n",
    "clf_stacking.fit(train_x,train_y)\n",
    "\n",
    "predictions_bagging = bagging_clf_rf.predict(test_x)\n",
    "predictions_boosting = boosting_clf_ada_boost.predict(test_x)\n",
    "predictions_stacking = clf_stacking.predict(test_x)\n",
    "\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_bagging),2),round(accuracy_score(test_y,predictions_bagging),2)))\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_boosting),2),round(accuracy_score(test_y,predictions_boosting),2)))\n",
    "print(\"For Stacking : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_stacking),2),round(accuracy_score(test_y,predictions_stacking),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway:\n",
    "\n",
    "Looking the comparison of the three ensemble methods, we see that the best performing method is the Stacking method with the highest accurcy score. However, the boosting method is a close second, with Bagging being the weakest. Despite this, all there methods can be considered as reletivally more effective in comparison to individual learner models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
